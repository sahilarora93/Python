{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import urllib\n",
    "import urllib2\n",
    "import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = \"http://www.pj.ma//pagesjaunes?\"\n",
    "# url_base = \"http://www.imdb.com/list/ls055386972/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PJ(object):\n",
    "    \"\"\"\n",
    "        PJ object that executes queries and returns set of results\n",
    "        \n",
    "        URL templates to make PJ searches.\n",
    "            http://www.pj.ma/pagesjaunes?page=2&pro_quiquoi=ophtalmologue&pro_ou=Casablanca\n",
    "            http://www.google.com/search?\n",
    "            page=page number\n",
    "            &pro_quiquoi= object of search\n",
    "            &pro_ou= location\n",
    "    \"\"\"\n",
    "    def __init__(self, pause=5.0, page=1, query=\"\", location=\"\"):\n",
    "        \"\"\"\n",
    "            @type  pause: long\n",
    "            @param url: not to burden the server\n",
    "            @type  page: int\n",
    "            @param page: pagination \n",
    "            @type  query: str\n",
    "            @param query: the object of the search\n",
    "            @type  location: str\n",
    "            @param location: where to look\n",
    "        \n",
    "            @rtype:  object\n",
    "            @return: the instance of PJ\n",
    "        \"\"\"\n",
    "        self.pause = pause\n",
    "        self.page = page        \n",
    "        self.query = query\n",
    "        self.location = location\n",
    "        \n",
    "    def set_pause(self, pause):\n",
    "        self.pause = pause\n",
    "\n",
    "    def set_page(self, page = 0):        \n",
    "        self.page = next if page > 0 else self.page + 1  \n",
    "    \n",
    "    def get_page(self):\n",
    "        return self.page\n",
    "    \n",
    "    def set_query(self, query):\n",
    "        self.query = query\n",
    "    \n",
    "    def set_location(self, location):\n",
    "        self.location = location \n",
    "    \n",
    "    def __url_contruction(self):\n",
    "        \"\"\"\n",
    "        Construct the search url\n",
    "        \"\"\"                                  \n",
    "        url_search = url_base\n",
    "        #page\n",
    "        page = \"page=%(page)s&\" % {\"page\":self.page}        \n",
    "        url_search += page\n",
    "        # pro_quiquoi        \n",
    "        query = \"pro_quiquoi=%(query)s&\" % {\"query\":self.query}\n",
    "        url_search += query\n",
    "        # pro_ou\n",
    "        location = \"pro_ou=%(location)s&\" % {\"location\":self.location}\n",
    "        url_search += location\n",
    "        return url_search        \n",
    "        \n",
    "    # Returns a generator that yields URLs.\n",
    "    def search(self, file=None):\n",
    "        \"\"\"\n",
    "        Returns search results for the current query as a iterator.                \n",
    "        \"\"\"            \n",
    "        # pause, so as to not overburden PJ\n",
    "        #time.sleep(self.pause+(random.random()-0.5)*5)                        \n",
    "    \n",
    "        # Prepare the URL of the first request.\n",
    "        url_search = self.__url_contruction()\n",
    "        print url_search\n",
    "        # Request the PJ Search results page.\n",
    "        stat = True\n",
    "        while stat:\n",
    "            try:\n",
    "                html = self.__get_result(url_search)\n",
    "                # Parse the response and extract the summaries\n",
    "                soup = BeautifulSoup(html)\n",
    "                if soup.findAll(text=re.compile(\"captcha\")) != []:                    \n",
    "                    print \"Failed page \"+self.get_page()+\", captcha retrying\"\n",
    "                else:\n",
    "                    stat = False\n",
    "            except:\n",
    "                print \"Failed page \"+self.get_page()+\", retrying\"\n",
    "                time.sleep(4)            \n",
    "        \n",
    "        if soup.findAll(text=re.compile(\"cette recherche\")) != []:\n",
    "            print soup.findAll(text=re.compile(\"cette recherche\"))\n",
    "            return False\n",
    "        \n",
    "        for table in soup.findAll(\"li\", {\"class\": \"gauchezonebcenter\"}):\n",
    "            result = \"\"\n",
    "            try :\n",
    "                prof = ' '.join(re.findall('\\w+', table.findNext(\"h2\", {\"class\": \"annoncesd-ttre\"}).a.findNext(text=True)))                                  \n",
    "                result += prof + ' | '\n",
    "                activity = ' '.join(re.findall('\\w+', table.findNext(\"div\", {\"class\": \"annoncesd-Activite\"}).span.findNextSiblings(text=True)[0]))\n",
    "                result += activity + ' | '\n",
    "                address_phone = table.findNext(\"li\", {\"class\": \"annoncesd-adressec\"})\n",
    "                glo_address = address_phone.div.div\n",
    "                address = ' '.join(re.findall('\\w+', glo_address.next.string))\n",
    "                result += address + ' | '\n",
    "                city = ' '.join(re.findall('\\w+', glo_address.strong.string))\n",
    "                result += city + ' | '\n",
    "                phones = address_phone.span.findNextSibling('strong')\n",
    "                phone1 = ' '.join(re.findall('\\w+', phones.string))                \n",
    "                result += phone1 + ' | '\n",
    "                phone2 = ' '.join(re.findall('\\w+', phones.findNextSibling('strong').string))\n",
    "                result += phone2 + ' | '                          \n",
    "            except :\n",
    "                pass\n",
    "            pickle.dump(result, file)\n",
    "        return True\n",
    "    \n",
    "        \n",
    "    # Request the given URL and return the response page, using the cookie jar.\n",
    "    def __get_result(self, url):\n",
    "        \"\"\"\n",
    "        Request the given URL and return the response page, using the cookie jar.\n",
    "    \n",
    "        @type  url: str\n",
    "        @param url: URL to retrieve.\n",
    "    \n",
    "        @rtype:  str\n",
    "        @return: Web page retrieved for the given URL.\n",
    "    \n",
    "        @raise IOError: An exception is raised on error.\n",
    "        @raise urllib2.URLError: An exception is raised on error.\n",
    "        @raise urllib2.HTTPError: An exception is raised on error.\n",
    "        \"\"\"\n",
    "        request = urllib2.Request(url)\n",
    "        request.add_header('User-Agent',\n",
    "                           'Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0)')        \n",
    "        response = urllib2.urlopen(request)        \n",
    "        html = response.read()\n",
    "        response.close()        \n",
    "        return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.pj.ma//pagesjaunes?page=1&pro_quiquoi=medecin&pro_ou=&\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file /usr/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.pj.ma//pagesjaunes?page=2&pro_quiquoi=medecin&pro_ou=&\n",
      "http://www.pj.ma//pagesjaunes?page=3&pro_quiquoi=medecin&pro_ou=&\n",
      "http://www.pj.ma//pagesjaunes?page=4&pro_quiquoi=medecin&pro_ou=&\n",
      "http://www.pj.ma//pagesjaunes?page=5&pro_quiquoi=medecin&pro_ou=&\n",
      "http://www.pj.ma//pagesjaunes?page=6&pro_quiquoi=medecin&pro_ou=&\n",
      "http://www.pj.ma//pagesjaunes?page=7&pro_quiquoi=medecin&pro_ou=&\n",
      "http://www.pj.ma//pagesjaunes?page=8&pro_quiquoi=medecin&pro_ou=&\n",
      "http://www.pj.ma//pagesjaunes?page=9&pro_quiquoi=medecin&pro_ou=&\n",
      "http://www.pj.ma//pagesjaunes?page=10&pro_quiquoi=medecin&pro_ou=&\n",
      "http://www.pj.ma//pagesjaunes?page=11&pro_quiquoi=medecin&pro_ou=&\n",
      "[u'Pas de r\\xe9sultats pour cette recherche.']\n"
     ]
    }
   ],
   "source": [
    "# When run as a script, take all arguments as a search query and run it.\n",
    "if __name__ == \"__main__\":    \n",
    "    prof = open(\"medecins.txt\", \"w\")    \n",
    "    query = 'medecin'\n",
    "    pj = PJ()\n",
    "    pj.set_query(query)\n",
    "    stat = True        \n",
    "    while stat:\n",
    "        stat = pj.search(prof)\n",
    "        pj.set_page()\n",
    "    prof.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
